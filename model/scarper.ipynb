{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import glob\n",
    "\n",
    "# import urllib.request\n",
    "# from bs4 import BeautifulSoup\n",
    "# from google_images_download import google_images_download\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imshow,imread\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "# from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Scrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = google_images_download.googleimagesdownload()   #class instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def google_scrapper(yoga_pose_name_prefix):\n",
    "#     for search_url,name_prefix in yoga_pose_name_prefix:\n",
    "#         arguments = {\"keywords\":search_url,\n",
    "#                      \"limit\":1200,\n",
    "#                      \"print_urls\":True,\n",
    "#                      \"prefix\":name_prefix,\n",
    "#                     \"image_directory\":name_prefix,\n",
    "#                     \"chromedriver\":\"C://Users//m_mas//Desktop//Songs//chromedriver_win32//chromedriver.exe\"}\n",
    "#         paths = response.download(arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yoga_poses = [('warrior 1 yoga pose','warrior_1'), ('warrior 2 yoga pose','warrior_2'), ('upward dog','upward_dog'),\n",
    "#               ('downward dog yoga pose','downward_dog'), ('triangle yoga pose','triangle'),('tree yoga pose','tree')]\n",
    "# # yoga_poses = [('triangle yoga pose','triangle')]\n",
    "# google_scrapper(yoga_poses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping Bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_bing(url):\n",
    "    \n",
    "#     resp = requests.get(url)\n",
    "#     page = resp.text\n",
    "\n",
    "#     soup = BeautifulSoup(page, 'html.parser')\n",
    "#     found = soup.findAll(\"div\", {\"class\": \"cico\"})\n",
    "    \n",
    "#     img_url = []\n",
    "#     for image in found:\n",
    "#         img_url.append(image.img['src'])\n",
    "\n",
    "#     for url in img_url:\n",
    "#         img_name = random.randrange(100,500)\n",
    "#         full_name = str(img_name)+'.jpg'\n",
    "#         file_name, headers = urllib.request.urlretrieve(url, full_name)\n",
    "        \n",
    "# url = 'https://www.bing.com/images/search?q=tree%20yoga%20pose&qs=n&form=QBIRMH&sp=-1&pq=tree%20yoga%20pose&sc=3-14&sk=&cvid=90B154DD33F34459ADCA6A54FF02BA34'\n",
    "# scrape_bing(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bing_url = ['https://www.bing.com/images/search?q=warrior+1+yoga+pose&qs=n&form=QBIR&sp=-1&pq=warrior%201%20yoga%20pose&sc=3-19&cvid=37C18880D7F1498597B57C14621BD953&first=1&cw=1349&ch=625',\n",
    "#             'https://www.bing.com/images/search?q=warrior%202%20yoga%20pose&qs=n&form=QBIR&sp=-1&pq=warrior%202%20yoga%20pose&sc=3-19&sk=&cvid=575241DC2FFC46EAAA5BB598EDB6DBCD',\n",
    "#            'https://www.bing.com/images/search?q=upward+dog+yoga&qs=CustomSearch&pq=upward+dog+&sc=8-11&cvid=FDC8B107D41F4DE18291249E8663DF51&sp=1&form=QBIR',\n",
    "#            'https://www.bing.com/images/search?q=downward%20dog%20yoga&qs=n&form=QBIR&sp=-1&pq=downward%20dog%20yoga&sc=8-17&sk=&cvid=B196CFE2D2BE46178076752B58CE07F4',\n",
    "#            'https://www.bing.com/images/search?q=Triangle+Yoga+Pose&FORM=RESTAB',\n",
    "#            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation - ONLY Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_ylabel = [('downward_dog', 'Downward Dog'),\n",
    "#                     ('tree', 'Tree'),\n",
    "#                     ('triangle','Trianlge'),\n",
    "#                     ('upward_dog','Upward-dog'),\n",
    "#                     ('warrior_1','Warrior 1'),\n",
    "#                     ('warrior_2','Warrior 2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#         rotation_range=40,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for directory_name, ylable in directory_ylabel:\n",
    "#     url = \"C://Users//m_mas//Desktop//Bitmaker_DSI//submit-sara//capstone//data//train//\"+directory_name+\"//\"\n",
    "#     files = glob.glob(url+\"*\")\n",
    "    \n",
    "#     for file in files:\n",
    "#         try:\n",
    "#             img = imread(file)\n",
    "#             x = img.reshape((1,) + img.shape)\n",
    "            \n",
    "#             i = 0\n",
    "#             for batch in datagen.flow(x, batch_size=1,\n",
    "#                                       save_to_dir=url, save_prefix='test'):\n",
    "#                 i += 1\n",
    "#                 if i > 2:\n",
    "#                     break  # otherwise the generator would loop indefinitely\n",
    "                \n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in training and testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_ylabel = [('downward_dog', 'Downward Dog'),\n",
    "                    ('tree', 'Tree'),\n",
    "                    ('triangle','Trianlge'),\n",
    "                    ('upward_dog','Upward-dog'),\n",
    "                    ('warrior_1','Warrior 1'),\n",
    "                    ('warrior_2','Warrior 2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_gray(type_, X_list,y_list, directory_ylabel):\n",
    "    for directory, y_label in directory_ylabel:\n",
    "        url = \"C://Users//m_mas//Desktop//Bitmaker_DSI//submit-sara//capstone//data//\"+type_+\"//\"+directory+\"//\"\n",
    "        files = glob.glob(url+\"*\")\n",
    "\n",
    "        for file in files:\n",
    "            try:\n",
    "                img = imread(file)\n",
    "                img = rgb2gray(resize(img,(200,200),anti_aliasing=True))\n",
    "                X_list.append(img)\n",
    "                y_list.append(y_label)\n",
    "                counter = counter +1\n",
    "            except:\n",
    "                pass\n",
    "    return(X_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list, y_list = resize_gray(type_ = \"test\", \n",
    "                             X_list = X_test,\n",
    "                             y_list= y_test,\n",
    "                             directory_ylabel = directory_ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_list)\n",
    "y_test = np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(X_test[8].shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list, y_list = resize_gray(type_ = \"train\", \n",
    "                             X_list = X_train,\n",
    "                             y_list= y_train,\n",
    "                             directory_ylabel = directory_ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_list)\n",
    "y_train = np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(X_train):\n",
    "    if x.shape != (200, 200):\n",
    "        print(i)\n",
    "        print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train[0].shape)\n",
    "print(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = X_train.reshape(X_train.shape[0], 200*200)\n",
    "Z_test = X_test.reshape(X_test.shape[0], 200*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "Z_train = scaler.fit_transform(Z_train)\n",
    "Z_test = scaler.transform(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure each value is a float. (Otherwise, we get an error.)\n",
    "Z_train = X_train.astype('float32')\n",
    "Z_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Z_train.shape)\n",
    "print(Z_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape each image to be 28 x 28 x 1.\n",
    "Z_train = Z_train.reshape(Z_train.shape[0], 200, 200, 1)\n",
    "Z_test = Z_test.reshape(Z_test.shape[0], 200, 200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y__train = y_train\n",
    "y__test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y__train = lb.fit_transform(y__train)\n",
    "y__test = lb.transform(y__test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.inverse_transform(y_train[[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = imshow(X_train[3])\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y__train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORK!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate Model\n",
    "\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "cnn_model.add(Conv2D(filters = 6,\n",
    "                     kernel_size = 3,\n",
    "                     activation = \"relu\",\n",
    "                    input_shape=(200,200,1)))\n",
    "\n",
    "# Add a pooling layer\n",
    "cnn_model.add(MaxPooling2D(pool_size = (1,1)))\n",
    "\n",
    "# # Add a second convolutional layer\n",
    "# cnn_model.add(Conv2D(kernel_size = 3,\n",
    "#                      filters = 16,\n",
    "#                      activation = \"relu\"))\n",
    "\n",
    "# # Add a second pooling layer\n",
    "# cnn_model.add(MaxPooling2D(pool_size = (1,1)))\n",
    "\n",
    "# Add a third convolutional layer\n",
    "cnn_model.add(Conv2D(kernel_size = 3,\n",
    "                     filters = 26,\n",
    "                     activation = \"relu\"))\n",
    "\n",
    "# Add a third pooling layer\n",
    "cnn_model.add(MaxPooling2D(pool_size = (1,1)))\n",
    "\n",
    "# Flatten the 3D array to 1D array\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "# Add in first perceptrons\n",
    "cnn_model.add(Dense(128, activation = \"relu\"))\n",
    "\n",
    "# Add in a Dropout\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Add in second perceptrons\n",
    "cnn_model.add(Dense(64, activation = \"relu\"))\n",
    "\n",
    "# Add in a second Dropout\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output\n",
    "cnn_model.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer = 'adam',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(Z_train,\n",
    "                       y__train,\n",
    "                       batch_size=150,\n",
    "                       validation_data = (Z_test, y__test),\n",
    "                       epochs = 10,\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Plot Training and Testing Loss:\n",
    "\n",
    "# Check out our train loss and test loss over epochs.\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Set figure size.\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Generate line plot of training, testing loss over epochs.\n",
    "plt.plot(train_loss, label='Training Loss', color='#185fad')\n",
    "plt.plot(test_loss, label='Testing Loss', color='orange')\n",
    "\n",
    "# Set title\n",
    "plt.title('Training and Testing Loss by Epoch', fontsize = 25)\n",
    "plt.xlabel('Epoch', fontsize = 18)\n",
    "plt.ylabel('Categorical Crossentropy', fontsize = 18)\n",
    "plt.xticks([0, 1, 2, 3, 4])\n",
    "\n",
    "plt.legend(fontsize = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
